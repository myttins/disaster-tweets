{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Natural Language Processing with Disaster Tweets\n# 1. Introduction\nIn this project, we tackle the Kaggle competition \"Natural Language Processing with Disaster Tweets.\" The challenge is to build a model that can predict whether a given tweet is about a real disaster (target = 1) or not (target = 0). This task is essential in real-world applications for quickly identifying urgent information during disasters.\n\n## Dataset Overview\n\n* Training Set: Contains 7,613 tweets with labels.\n* Test Set: Contains 3,263 tweets without labels (used for submission).\n* Features:\n    * id: Unique identifier for each tweet.\n    * text: The tweet content.\n    * location: The location the tweet was sent from (may be null).\n    * keyword: A particular keyword from the tweet (may be null).\n    * target: 1 if the tweet is about a real disaster, 0 otherwise (only in training data).\n# 2. Exploratory Data Analysis (EDA)\n## Loading Libraries and Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ntrain = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Inspection","metadata":{}},{"cell_type":"code","source":"print(\"Training Data Shape:\", train.shape)\nprint(\"Test Data Shape:\", test.shape)\nprint(\"Unique target values:\", train['target'].unique())\nprint(\"Value counts:\\n\", train['target'].value_counts())\ntrain.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Missing Values","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Observations:\n* location and keyword have missing values.\n* text and target are complete.","metadata":{}},{"cell_type":"markdown","source":"## Target Distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.countplot(x='target', data=train)\nplt.title('Distribution of Disaster vs. Non-Disaster Tweets')\nplt.xlabel('Target')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Observation: The classes are slightly imbalanced.","metadata":{}},{"cell_type":"markdown","source":"## Word Cloud Visualization","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\n\n# Disaster tweets\ndisaster_tweets = train[train['target'] == 1]['text'].values\nnon_disaster_tweets = train[train['target'] == 0]['text'].values\n\n# Generate word clouds\ndef generate_wordcloud(text, title):\n    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(' '.join(text))\n    plt.figure()\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()\n\ngenerate_wordcloud(disaster_tweets, 'Disaster Tweets')\ngenerate_wordcloud(non_disaster_tweets, 'Non-Disaster Tweets')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Cleaning Plan\n\nBased on EDA, we plan to:\n\n* Clean the text data by:\n    * Removing URLs, HTML tags, and mentions.\n    * Handling contractions (e.g., \"don't\" to \"do not\").\n    * Removing punctuation and special characters.\n    * Converting text to lowercase.\n* Tokenization: Split text into tokens.\n* Word Embedding: Use Word2Vec embeddings to represent words in vectors.","metadata":{}},{"cell_type":"markdown","source":"# 3. Data Preprocessing\n## Text Cleaning Function","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'https?://\\S+', '', text)  # Remove URLs\n    text = re.sub(r'<.*?>', '', text)         # Remove HTML tags\n    text = re.sub(r'@[A-Za-z0-9_]+', '', text) # Remove mentions\n    text = re.sub(r'[^a-zA-Z]', ' ', text)    # Remove punctuation\n    text = text.split()\n    text = [word for word in text if word not in stop_words]\n    text = ' '.join(text)\n    return text\n\ntrain['clean_text'] = train['text'].apply(clean_text)\ntest['clean_text'] = test['text'].apply(clean_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenization and Sequencing","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Initialize the tokenizer\nvocab_size = 10000  # You can adjust this value\ntokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\ntokenizer.fit_on_texts(train['clean_text'])\n\n# Convert text to sequences\nX_train_sequences = tokenizer.texts_to_sequences(train['clean_text'])\nX_test_sequences = tokenizer.texts_to_sequences(test['clean_text'])\n\n# Pad sequences to ensure equal length\nmax_length = 100  # You can adjust this based on the data\nX_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding='post')\nX_test_padded = pad_sequences(X_test_sequences, maxlen=max_length, padding='post')\n\n# Target variable\ny_train = train['target'].values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Word Embedding with Word2Vec\n\nWe will use pre-trained Word2Vec embeddings to represent words.\n\n* Word2Vec: An embedding method that maps words into vector space, capturing semantic meaning.","metadata":{}},{"cell_type":"code","source":"# import gensim.downloader as api\n\n# word2vec = api.load('word2vec-google-news-300')\n\n# embedding_dim = 300\nvocab_size = len(tokenizer.word_index) + 1\n\n# # Create embedding matrix\n# embedding_matrix = np.zeros((vocab_size, embedding_dim))\n# for word, i in tokenizer.word_index.items():\n#     if word in word2vec:\n#         embedding_matrix[i] = word2vec[word]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Model Architectures\nWe will build and compare three different RNN models:\n\n* Model 1: LSTM\n* Model 2: GRU\n* Model 3: Bidirectional LSTM\n\n## Common Model Components\n\n* Embedding Layer: Transforms integer representations into dense vectors of fixed size.\n* RNN Layer: Captures sequential information.\n* Dense Layer: Outputs the final prediction.\n\n## Model 1: LSTM\n\nAn LSTM (Long Short-Term Memory) network is a type of RNN capable of learning long-term dependencies. It mitigates the vanishing gradient problem, making it suitable for text data where context from earlier words can be important.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n\nmodel_lstm = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length),\n    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n    Dense(1, activation='sigmoid')\n])\n\nmodel_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_lstm.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model 2: GRU\n\nA GRU (Gated Recurrent Unit) is a gating mechanism in RNNs that, like LSTM, helps to solve the vanishing gradient problem. It has fewer parameters than LSTM, which can lead to faster training times.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import GRU\n\nmodel_gru = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length),\n    GRU(128, dropout=0.2, recurrent_dropout=0.2),\n    Dense(1, activation='sigmoid')\n])\n\nmodel_gru.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_gru.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model 3: Bidirectional LSTM\n\nA Bidirectional LSTM processes the sequence both forward and backward, capturing information from past and future states. This can be beneficial when the context after a word is important for understanding.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Bidirectional\n\nmodel_bi_lstm = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length),\n    Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)),\n    Dense(1, activation='sigmoid')\n])\n\nmodel_bi_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_bi_lstm.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Training and Evaluation\n\n## Splitting the Data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training and validation sets\nX_train, X_val, y_train_split, y_val = train_test_split(X_train_padded, y_train, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training the Models\n\nHyperparameters\n* Batch Size: 64\n* Epochs: 5","metadata":{}},{"cell_type":"code","source":"#Model 1: LSTM\nhistory_lstm = model_lstm.fit(X_train, y_train_split, epochs=5, batch_size=64, validation_data=(X_val, y_val))\n\n#Model 2: GRU\nhistory_gru = model_gru.fit(X_train, y_train_split, epochs=5, batch_size=64, validation_data=(X_val, y_val))\n\n#Model 3: Bidirectional LSTM\nhistory_bi_lstm = model_bi_lstm.fit(X_train, y_train_split, epochs=5, batch_size=64, validation_data=(X_val, y_val))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Analysis\n\nObservation: The model shows improvement over epochs.","metadata":{}},{"cell_type":"markdown","source":"# 6. Evaluation and Results\n\nModel 1: LSTM","metadata":{}},{"cell_type":"code","source":"val_loss_lstm, val_acc_lstm = model_lstm.evaluate(X_val, y_val)\n\n# Plot accuracy\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history_lstm.history['accuracy'], label='Train Accuracy')\nplt.plot(history_lstm.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model 1: LSTM Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(history_lstm.history['loss'], label='Train Loss')\nplt.plot(history_lstm.history['val_loss'], label='Validation Loss')\nplt.title('Model 1: LSTM Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\nprint(f\"LSTM Validation Accuracy: {val_acc_lstm:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model 2: GRU","metadata":{}},{"cell_type":"code","source":"val_loss_gru, val_acc_gru = model_gru.evaluate(X_val, y_val)\n\n# Plot accuracy\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history_gru.history['accuracy'], label='Train Accuracy')\nplt.plot(history_gru.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model 2: GRU Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(history_gru.history['loss'], label='Train Loss')\nplt.plot(history_gru.history['val_loss'], label='Validation Loss')\nplt.title('Model 2: GRU Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\nprint(f\"GRU Validation Accuracy: {val_acc_gru:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model 3: Bidirectional LSTM","metadata":{}},{"cell_type":"code","source":"val_loss_bi_lstm, val_acc_bi_lstm = model_bi_lstm.evaluate(X_val, y_val)\n\n# Plot accuracy\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history_bi_lstm.history['accuracy'], label='Train Accuracy')\nplt.plot(history_bi_lstm.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model 3: Bidirectional LSTM Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(history_bi_lstm.history['loss'], label='Train Loss')\nplt.plot(history_bi_lstm.history['val_loss'], label='Validation Loss')\nplt.title('Model 3: Bidirectional LSTM Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\nprint(f\"Bidirectional LSTM Validation Accuracy: {val_acc_bi_lstm:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Comparing the Models","metadata":{}},{"cell_type":"code","source":"results = pd.DataFrame({\n    'Model': ['LSTM', 'GRU', 'Bidirectional LSTM'],\n    'Validation Accuracy': [val_acc_lstm, val_acc_gru, val_acc_bi_lstm],\n    'Validation Loss': [val_loss_lstm, val_loss_gru, val_loss_bi_lstm]\n})\n\nresults","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Comparing the Models Visually\n\nWe can also plot the validation accuracy of all models in a single plot for direct comparison.","metadata":{}},{"cell_type":"code","source":"# Plot validation accuracy of all models\nplt.figure(figsize=(8, 6))\nplt.plot(history_lstm.history['val_accuracy'], label='LSTM')\nplt.plot(history_gru.history['val_accuracy'], label='GRU')\nplt.plot(history_bi_lstm.history['val_accuracy'], label='Bidirectional LSTM')\nplt.title('Validation Accuracy Comparison')\nplt.xlabel('Epoch')\nplt.ylabel('Validation Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Interpretation:\n\n* This plot allows us to see which model consistently performs better across epochs.\n* The model with the highest validation accuracy curve is likely the best performer.\n* Similarly, we can plot the validation loss:","metadata":{}},{"cell_type":"code","source":"# Plot validation loss of all models\nplt.figure(figsize=(8, 6))\nplt.plot(history_lstm.history['val_loss'], label='LSTM')\nplt.plot(history_gru.history['val_loss'], label='GRU')\nplt.plot(history_bi_lstm.history['val_loss'], label='Bidirectional LSTM')\nplt.title('Validation Loss Comparison')\nplt.xlabel('Epoch')\nplt.ylabel('Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Interpretation:\n\n* Lower validation loss indicates better model performance.\n* Comparing the curves helps identify which model converges faster and generalizes better.\n* Observation: Training and validation accuracy increase over epochs; loss decreases.","metadata":{}},{"cell_type":"markdown","source":"## Predictions on Test Data","metadata":{}},{"cell_type":"code","source":"predictions = model_bi_lstm.predict(X_test_padded)\npredictions = (predictions > 0.5).astype(int).reshape(-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"# Create a submission DataFrame\nsubmission = pd.DataFrame({'id': test['id'], 'target': predictions})\nsubmission.to_csv('submission.csv', index=False)\n\n# Display the first few rows\nsubmission.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Conclusion\nIn this project, we built an LSTM-based neural network to classify disaster-related tweets. Key takeaways include:\n\n* Data Cleaning significantly impacts model performance.\n* Word Embeddings like Word2Vec help in capturing semantic meaning.\n* LSTM Networks are effective for text classification tasks.\n* Hyperparameter Tuning and Regularization (Dropout) improve model generalization.\n\nFuture Improvements\n\n* Experiment with GRU or Bidirectional LSTM for potential performance gains.\n* Use More Advanced Embeddings like GloVe or BERT.\n* Hyperparameter Optimization using tools like GridSearchCV or Bayesian Optimization.\n\nReferences\n* Kaggle Competition: [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started)\n* TensorFlow Keras Documentation: [Recurrent Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Recurrent)\n* Word2Vec: [Google's Word2Vec Model](https://code.google.com/archive/p/word2vec/)","metadata":{}}]}